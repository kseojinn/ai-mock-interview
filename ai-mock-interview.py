# í•œêµ­ì–´ ìµœì í™” Ollama ë©´ì ‘ ì‹œìŠ¤í…œ
# ollama_interview_korean.py

import streamlit as st
import requests
import json
import time
from datetime import datetime

# Ollama API ì„¤ì •
OLLAMA_BASE_URL = "http://localhost:11434"
MODEL_NAME = "qwen2.5:7b"  # í˜„ì¬ ì‘ë™í•˜ëŠ” ëª¨ë¸

class OllamaInterviewSystem:
    def __init__(self):
        self.conversation_history = []
        self.interview_type = None
        self.question_count = 0
        self.max_questions = 8
        
    def check_ollama_connection(self):
        """Ollama ì„œë²„ ì—°ê²° í™•ì¸"""
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_available_models(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                return [model["name"] for model in models]
            return []
        except:
            return []
    
    def call_ollama(self, prompt: str) -> str:
        """Ollama API í˜¸ì¶œ - í•œêµ­ì–´ ìµœì í™”"""
        try:
            # í•œêµ­ì–´ ê°•ì œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            korean_prompt = f"""ë‹¤ìŒ ì§€ì‹œì‚¬í•­ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
1. ì˜¤ì§ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”
2. ì¼ë³¸ì–´, ì¤‘êµ­ì–´, ì˜ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”
4. í•œêµ­ì˜ ë©´ì ‘ê´€ì²˜ëŸ¼ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”

{prompt}

ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": MODEL_NAME,
                    "prompt": korean_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": 500
                    }
                },
                timeout=360
            )
            
            if response.status_code == 200:
                return response.json()["response"].strip()
            else:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except requests.exceptions.Timeout:
            return "ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def get_interview_prompt(self, interview_type: str, is_first: bool = False) -> str:
        """ë©´ì ‘ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„± - í•œêµ­ì–´ íŠ¹í™”"""
        
        type_prompts = {
            "ê³µë¬´ì›": """ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ê¸°ê´€ì˜ ê²½í—˜ì´ í’ë¶€í•œ ê³µë¬´ì› ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê³µì§ê°€ì¹˜, ë´‰ì‚¬ì •ì‹ , ê³µì •ì„±, ì²­ë ´ì„±ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ì§€ì›ë™ê¸°, ê³µì§ê´€, ê°ˆë“±í•´ê²°, ì‹œë¯¼ì„œë¹„ìŠ¤, ì •ì±…ì´í•´ë„, êµ­ë¯¼ì— ëŒ€í•œ ë´‰ì‚¬ì •ì‹ """,
            
            "ê³µê¸°ì—…": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê³µê¸°ì—… ì¸ì‚¬ë‹´ë‹¹ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê³µê³µì„±ê³¼ íš¨ìœ¨ì„±, ì „ë¬¸ì„±ê³¼ í˜ì‹ ì„ ê· í˜•ìˆê²Œ í‰ê°€í•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ê¸°ì—…ì´í•´ë„, ì „ë¬¸ì„±, ì‚¬íšŒì ì±…ì„, í˜ì‹ ì•„ì´ë””ì–´, ì¡°ì§ì í•©ì„±, ê³µê¸°ì—… ì—­í• """,
            
            "IT": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ìœ ëª…í•œ IT ê¸°ì—… ê¸°ìˆ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê¸°ìˆ ì—­ëŸ‰, ë¬¸ì œí•´ê²°ëŠ¥ë ¥, í•™ìŠµëŠ¥ë ¥, í˜‘ì—…ëŠ¥ë ¥ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ê¸°ìˆ ê²½í—˜, í”„ë¡œì íŠ¸ì‚¬ë¡€, ë¬¸ì œí•´ê²°, ìµœì‹ ê¸°ìˆ ë™í–¥, íŒ€ì›Œí¬, ì½”ë”©ì‹¤ë ¥""",
            
            "ì‚¬ê¸°ì—…": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ëŒ€ê¸°ì—… ì¸ì‚¬ë‹´ë‹¹ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ì„±ê³¼ì§€í–¥ì„±, ì ì‘ë ¥, ë¦¬ë”ì‹­, íšŒì‚¬ê¸°ì—¬ë„ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ì§€ì›ë™ê¸°, ì„±ì·¨ê²½í—˜, ëª©í‘œì˜ì‹, ìŠ¤íŠ¸ë ˆìŠ¤ê´€ë¦¬, ë¯¸ë˜ê³„íš, íšŒì‚¬ì í•©ì„±"""
        }
        
        base_prompt = f"""{type_prompts[interview_type]}

ì¤‘ìš”í•œ ë©´ì ‘ ì§„í–‰ ì§€ì¹¨:
- ë°˜ë“œì‹œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ëŒ€í™”í•˜ì„¸ìš” (ì ˆëŒ€ ì¼ë³¸ì–´, ì¤‘êµ­ì–´, ì˜ì–´ ê¸ˆì§€)
- ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ ì¡´ëŒ“ë§ ì‚¬ìš©
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ëª…í™•í•œ ì§ˆë¬¸ë§Œ ì œì‹œ
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ ìœ„ì£¼
- ì§€ì›ì ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°± ì œê³µ
- í•œêµ­ì˜ ë©´ì ‘ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”

í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒí™©: {self.question_count + 1}ë²ˆì§¸ ì§ˆë¬¸ (ì´ {self.max_questions}ê°œ ì˜ˆì •)"""

        if is_first:
            return f"""{base_prompt}

ì§€ê¸ˆ {interview_type} ë©´ì ‘ì„ ì‹œì‘í•©ë‹ˆë‹¤. 
í•œêµ­ì˜ ë©´ì ‘ê´€ë‹µê²Œ ì •ì¤‘í•œ ì¸ì‚¬ë§ê³¼ í•¨ê»˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì™¸êµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""
        else:
            recent_history = ""
            if self.conversation_history:
                recent = self.conversation_history[-2:]  # ìµœê·¼ 2ê°œ ëŒ€í™”
                for conv in recent:
                    recent_history += f"ë©´ì ‘ê´€: {conv['interviewer']}\nì§€ì›ì: {conv['user']}\n\n"
            
            return f"""{base_prompt}

ìµœê·¼ ëŒ€í™” ë‚´ìš©:
{recent_history}

ì§€ì›ìì˜ ë‹µë³€ì— ëŒ€í•´ ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ì£¼ê³ , ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì™¸êµ­ì–´ë¥¼ ì„ì§€ ë§ˆì„¸ìš”.
ë‹µë³€ì´ êµ¬ì²´ì ì´ê³  ì¢‹ë‹¤ë©´ ê²©ë ¤í•˜ê³ , ë¶€ì¡±í•˜ë‹¤ë©´ ë” ìì„¸í•œ ì„¤ëª…ì„ ì •ì¤‘í•˜ê²Œ ìš”ì²­í•˜ì„¸ìš”."""
    
    def start_interview(self, interview_type: str) -> str:
        """ë©´ì ‘ ì‹œì‘"""
        self.interview_type = interview_type
        self.conversation_history = []
        self.question_count = 0
        
        prompt = self.get_interview_prompt(interview_type, is_first=True)
        response = self.call_ollama(prompt)
        self.question_count = 1
        
        return response
    
    def process_answer(self, user_answer: str) -> tuple[str, bool]:
        """ë‹µë³€ ì²˜ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸"""
        if self.question_count >= self.max_questions:
            # ë©´ì ‘ ì¢…ë£Œ
            prompt = f"""ë©´ì ‘ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 
ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€: {user_answer}

í•œêµ­ì˜ ë©´ì ‘ê´€ë‹µê²Œ ì „ì²´ì ì¸ ë©´ì ‘ì— ëŒ€í•œ ì¢…í•© í”¼ë“œë°±ì„ ì •ì¤‘í•˜ê³  ë”°ëœ»í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì „ë°˜ì ì¸ ë©´ì ‘ íƒœë„ì™€ ì¸ìƒ
2. ì£¼ìš” ê°•ì  2-3ê°€ì§€
3. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ 1-2ê°€ì§€  
4. ì•ìœ¼ë¡œì˜ ë°œì „ì„ ìœ„í•œ ì¡°ì–¸
5. ê²©ë ¤ì™€ ì‘ì›ì˜ ë§ˆë¬´ë¦¬ ì¸ì‚¬

ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³  ê²©ë ¤ì˜ ë§ì”€ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”."""
            
            response = self.call_ollama(prompt)
            return response, True  # ë©´ì ‘ ì¢…ë£Œ
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        if self.conversation_history:
            self.conversation_history[-1]['user'] = user_answer
        
        # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
        prompt = self.get_interview_prompt(self.interview_type)
        prompt += f"\n\nì§€ì›ìì˜ ìµœê·¼ ë‹µë³€: {user_answer}\n\nì´ ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•œ í”¼ë“œë°±ê³¼ í•¨ê»˜ ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
        
        response = self.call_ollama(prompt)
        
        # ìƒˆë¡œìš´ ëŒ€í™” ì¶”ê°€
        self.conversation_history.append({
            'interviewer': response,
            'user': None
        })
        
        self.question_count += 1
        return response, False  # ë©´ì ‘ ê³„ì†

def main():
    st.set_page_config(
        page_title="AI ë©´ì ‘ ì‹œìŠ¤í…œ", 
        page_icon="ğŸ‡°ğŸ‡·",
        layout="wide"
    )
    
    st.title("AI ëª¨ì˜ ë©´ì ‘ ì‹œìŠ¤í…œ")
    st.caption("ğŸš€í•œêµ­ì–´ íŠ¹í™”")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'interview_system' not in st.session_state:
        st.session_state.interview_system = OllamaInterviewSystem()
    if 'interview_started' not in st.session_state:
        st.session_state.interview_started = False
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'interview_finished' not in st.session_state:
        st.session_state.interview_finished = False
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ì—°ê²° ìƒíƒœ í™•ì¸
        is_connected = st.session_state.interview_system.check_ollama_connection()
        if is_connected:
            st.success("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
            models = st.session_state.interview_system.get_available_models()
            if models:
                st.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\n{', '.join(models)}")
        else:
            st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.info("í•´ê²°ë°©ë²•:\n1. 'ollama serve' ì‹¤í–‰\n2. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨")
            return
        
        # ë©´ì ‘ ì„¤ì •
        if not st.session_state.interview_started:
            st.divider()
            st.subheader("ğŸ“‹ ë©´ì ‘ ì„¤ì •")
            
            interview_types = {
                "ğŸ›ï¸ ê³µë¬´ì›": "ê³µë¬´ì›",
                "ğŸ¢ ê³µê¸°ì—…": "ê³µê¸°ì—…", 
                "ğŸ’» IT": "IT",
                "ğŸª ì‚¬ê¸°ì—…": "ì‚¬ê¸°ì—…"
            }
            
            selected = st.selectbox(
                "ë©´ì ‘ ìœ í˜• ì„ íƒ:",
                options=list(interview_types.keys())
            )
            st.session_state.selected_type = interview_types[selected]
            
            st.info(f"""
**{interview_types[selected]} ë©´ì ‘ íŠ¹ì§•:**
- ì´ {st.session_state.interview_system.max_questions}ê°œ ì§ˆë¬¸ ì˜ˆì •
- í•œêµ­ì–´ íŠ¹í™” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ êµ¬ì²´ì  ì§ˆë¬¸
- ë‹µë³€ë³„ ì¦‰ì‹œ í”¼ë“œë°± ì œê³µ
            """)
        else:
            # ë©´ì ‘ ì§„í–‰ ìƒí™©
            st.subheader("ğŸ“Š ë©´ì ‘ ì§„í–‰ë¥ ")
            progress = st.session_state.interview_system.question_count
            max_q = st.session_state.interview_system.max_questions
            
            st.progress(progress / max_q)
            st.write(f"ì§„í–‰ë¥ : {progress}/{max_q}")
            st.write(f"ë©´ì ‘ ìœ í˜•: {st.session_state.interview_system.interview_type}")
            
            if st.button("ğŸ›‘ ë©´ì ‘ ì¤‘ë‹¨", type="secondary"):
                st.session_state.interview_started = False
                st.session_state.messages = []
                st.session_state.interview_finished = False
                st.rerun()
    
    # ë©”ì¸ ì½˜í…ì¸ 
    if not st.session_state.interview_started:
        # ì‹œì‘ í™”ë©´
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("### ğŸ¯ ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ!")
            
            if hasattr(st.session_state, 'selected_type'):
                st.info(f"**ì„ íƒëœ ë©´ì ‘:** {st.session_state.selected_type}")
                
                st.markdown("""
                **ğŸ’¡ ë©´ì ‘ ì§„í–‰ ë°©ì‹:**
- AI ë©´ì ‘ê´€ì´ ì™„ë²½í•œ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•©ë‹ˆë‹¤
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ ì „ë¬¸ì ì¸ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤  
- ê° ë‹µë³€ì— ëŒ€í•´ ì¦‰ì‹œ í•œêµ­ì–´ í”¼ë“œë°±ì„ ë°›ìŠµë‹ˆë‹¤
- í•œêµ­ì˜ ë©´ì ‘ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤
- ë©´ì ‘ ì™„ë£Œ í›„ ì¢…í•© í‰ê°€ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•©ë‹ˆë‹¤
                """)
                
                if st.button("ğŸš€ ë©´ì ‘ ì‹œì‘í•˜ê¸°!", type="primary", use_container_width=True):
                    with st.spinner("AI ë©´ì ‘ê´€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        response = st.session_state.interview_system.start_interview(
                            st.session_state.selected_type
                        )
                        st.session_state.messages = [
                            {"role": "assistant", "content": response, "timestamp": datetime.now()}
                        ]
                        st.session_state.interview_started = True
                        st.session_state.interview_finished = False
                    st.rerun()
    
    else:
        # ë©´ì ‘ ì§„í–‰ í™”ë©´
        st.markdown("### ğŸ’¬ ë©´ì ‘ ì§„í–‰")
        
        # ëŒ€í™” í‘œì‹œ
        for message in st.session_state.messages:
            if message["role"] == "assistant":
                with st.chat_message("assistant", avatar="ğŸ‡°ğŸ‡·"):
                    st.write(message["content"])
                    if "timestamp" in message:
                        st.caption(f"ğŸ• {message['timestamp'].strftime('%H:%M:%S')}")
            else:
                with st.chat_message("user", avatar="ğŸ‘¤"):
                    st.write(message["content"])
                    if "timestamp" in message:
                        st.caption(f"ğŸ• {message['timestamp'].strftime('%H:%M:%S')}")
        
        # ë‹µë³€ ì…ë ¥ (ë©´ì ‘ì´ ëë‚˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)
        if not st.session_state.interview_finished:
            with st.form("answer_form", clear_on_submit=True):
                user_input = st.text_area(
                    "ğŸ’­ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    height=120,
                    placeholder="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸ì— êµ¬ì²´ì ì´ê³  ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”...",
                    help="Enterë¥¼ ëˆŒëŸ¬ì„œ ì¤„ë°”ê¿ˆí•˜ê³ , ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë‹µë³€ì„ ì œì¶œí•˜ì„¸ìš”."
                )
                
                col1, col2 = st.columns([4, 1])
                with col1:
                    submitted = st.form_submit_button("ğŸ“¤ ë‹µë³€ ì œì¶œ", type="primary")
                with col2:
                    skip = st.form_submit_button("â­ï¸ ê±´ë„ˆë›°ê¸°")
                
                if submitted and user_input.strip():
                    # ì‚¬ìš©ì ë‹µë³€ ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "user", 
                        "content": user_input,
                        "timestamp": datetime.now()
                    })
                    
                    # AI ì‘ë‹µ ìƒì„±
                    with st.spinner("ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        ai_response, is_finished = st.session_state.interview_system.process_answer(user_input)
                    
                    # AI ì‘ë‹µ ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": ai_response,
                        "timestamp": datetime.now()
                    })
                    
                    if is_finished:
                        st.session_state.interview_finished = True
                        st.balloons()
                    
                    st.rerun()
                
                elif skip:
                    # ê±´ë„ˆë›°ê¸° ì²˜ë¦¬
                    skip_response, is_finished = st.session_state.interview_system.process_answer("ì£„ì†¡í•˜ì§€ë§Œ ì´ ì§ˆë¬¸ì€ ê±´ë„ˆë›°ê² ìŠµë‹ˆë‹¤.")
                    
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": skip_response,
                        "timestamp": datetime.now()
                    })
                    
                    if is_finished:
                        st.session_state.interview_finished = True
                    
                    st.rerun()
                
                elif submitted:
                    st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        else:
            # ë©´ì ‘ ì™„ë£Œ
            st.success("ğŸ‰ í•œêµ­ì–´ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("ğŸ”„ ìƒˆ ë©´ì ‘ ì‹œì‘", type="primary"):
                    st.session_state.interview_started = False
                    st.session_state.messages = []
                    st.session_state.interview_finished = False
                    st.rerun()
            
            with col2:
                # ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ
                if st.session_state.messages:
                    conversation_text = f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ AI ë©´ì ‘ ê¸°ë¡\n"
                    conversation_text += f"ë©´ì ‘ ìœ í˜•: {st.session_state.interview_system.interview_type}\n"
                    conversation_text += f"ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    conversation_text += "=" * 50 + "\n\n"
                    
                    for msg in st.session_state.messages:
                        role = "ğŸ‡°ğŸ‡· ë©´ì ‘ê´€" if msg["role"] == "assistant" else "ğŸ‘¤ ì§€ì›ì"
                        timestamp = msg.get("timestamp", datetime.now()).strftime('%H:%M:%S')
                        conversation_text += f"[{timestamp}] {role}:\n{msg['content']}\n\n"
                    
                    st.download_button(
                        label="ğŸ’¾ ë©´ì ‘ ê¸°ë¡ ì €ì¥",
                        data=conversation_text,
                        file_name=f"korean_interview_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
            
            with col3:
                st.metric("ì´ ì§ˆë¬¸ ìˆ˜", len([m for m in st.session_state.messages if m["role"] == "assistant"]))

if __name__ == "__main__":
    main()
