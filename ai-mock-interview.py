# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st          # ì›¹ ì¸í„°í˜ì´ìŠ¤ í”„ë ˆì„ì›Œí¬
import requests                 # HTTP ìš”ì²­ (Ollama API í†µì‹ )
import json                     # JSON ë°ì´í„° ì²˜ë¦¬
import time                     # ì‹œê°„ ê´€ë ¨ í•¨ìˆ˜
from datetime import datetime   # ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬

# =============================================================================
# ì „ì—­ ì„¤ì • ìƒìˆ˜
# =============================================================================

# Ollama ì„œë²„ API ì„¤ì •
OLLAMA_BASE_URL = "http://localhost:11434"  # Ollama ë¡œì»¬ ì„œë²„ ì£¼ì†Œ
MODEL_NAME = "qwen2.5:7b"                   # ì‚¬ìš©í•  AI ëª¨ë¸ëª… (í•œêµ­ì–´ íŠ¹í™”)

# =============================================================================
# ë©”ì¸ ë©´ì ‘ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
# =============================================================================

class OllamaInterviewSystem:
    """
    Ollama ê¸°ë°˜ AI ë©´ì ‘ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    - AI ëª¨ë¸ê³¼ì˜ í†µì‹  ê´€ë¦¬
    - ë©´ì ‘ ì§„í–‰ ìƒíƒœ ì¶”ì 
    - í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
    - ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    """
    
    def __init__(self):
        """
        ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        ì´ˆê¸°í™”ë˜ëŠ” ì†ì„±:
        - conversation_history: ëŒ€í™” ë‚´ì—­ ì €ì¥ ë¦¬ìŠ¤íŠ¸
        - interview_type: í˜„ì¬ ë©´ì ‘ ìœ í˜• (ê³µë¬´ì›/ê³µê¸°ì—…/IT/ì‚¬ê¸°ì—…)
        - question_count: í˜„ì¬ ì§ˆë¬¸ ë²ˆí˜¸
        - max_questions: ì´ ì§ˆë¬¸ ìˆ˜ ì œí•œ
        """
        self.conversation_history = []  # ë©´ì ‘ ëŒ€í™” ë‚´ì—­ ì €ì¥
        self.interview_type = None      # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë©´ì ‘ ìœ í˜•
        self.question_count = 0         # í˜„ì¬ ì§ˆë¬¸ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
        self.max_questions = 8          # ë©´ì ‘ ì´ ì§ˆë¬¸ ìˆ˜ (ì¡°ì • ê°€ëŠ¥)
        
    def check_ollama_connection(self):
        """
        Ollama ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸
        
        Returns:
            bool: ì—°ê²° ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
        """
        try:
            # Ollama APIì— ê°„ë‹¨í•œ GET ìš”ì²­ìœ¼ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
            return response.status_code == 200  # HTTP 200 OKë©´ ì—°ê²° ì„±ê³µ
        except:
            # ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, íƒ€ì„ì•„ì›ƒ ë“± ëª¨ë“  ì˜ˆì™¸ ìƒí™©ì—ì„œ False ë°˜í™˜
            return False
    
    def get_available_models(self):
        """
        Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        
        Returns:
            list: ì„¤ì¹˜ëœ ëª¨ë¸ëª… ë¦¬ìŠ¤íŠ¸, ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # Ollama APIì—ì„œ ëª¨ë¸ ëª©ë¡ ìš”ì²­
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags")
            if response.status_code == 200:
                models = response.json().get("models", [])
                # ëª¨ë¸ëª…ë§Œ ì¶”ì¶œí•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
                return [model["name"] for model in models]
            return []
        except:
            # API ìš”ì²­ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []
    
    def call_ollama(self, prompt: str) -> str:
        """
        Ollama APIë¥¼ í†µí•´ AI ëª¨ë¸ì—ê²Œ ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°
        
        Args:
            prompt (str): AIì—ê²Œ ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ (ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì§€ì‹œ)
            
        Returns:
            str: AIê°€ ìƒì„±í•œ ë©´ì ‘ê´€ ì‘ë‹µ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
        """
        try:
            # í•œêµ­ì–´ ê°•ì œ ì§€ì¹¨ì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            # ì´ ë¶€ë¶„ì´ í•œêµ­ì–´ í’ˆì§ˆì˜ í•µì‹¬!
            korean_prompt = f"""ë‹¤ìŒ ì§€ì‹œì‚¬í•­ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
1. ì˜¤ì§ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”
2. ì¼ë³¸ì–´, ì¤‘êµ­ì–´, ì˜ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì¡´ëŒ“ë§ë¡œ ëŒ€í™”í•˜ì„¸ìš”
4. í•œêµ­ì˜ ë©´ì ‘ê´€ì²˜ëŸ¼ ì •ì¤‘í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”

{prompt}

ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

            # Ollama APIì— POST ìš”ì²­ìœ¼ë¡œ AI ëª¨ë¸ í˜¸ì¶œ
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": MODEL_NAME,           # ì‚¬ìš©í•  AI ëª¨ë¸
                    "prompt": korean_prompt,       # í•œêµ­ì–´ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
                    "stream": False,               # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™” (ì „ì²´ ì‘ë‹µ í•œë²ˆì—)
                    "options": {
                        "temperature": 0.7,        # ì°½ì˜ì„± ìˆ˜ì¤€ (0.0~1.0)
                        "top_p": 0.9,             # ë‹¨ì–´ ì„ íƒ ë‹¤ì–‘ì„±
                        "max_tokens": 500         # ìµœëŒ€ ì‘ë‹µ ê¸¸ì´ ì œí•œ
                    }
                },
                timeout=360  # 6ë¶„ íƒ€ì„ì•„ì›ƒ (8GB RAM ê³ ë ¤)
            )
            
            # API ì‘ë‹µ ì²˜ë¦¬
            if response.status_code == 200:
                # ì •ìƒ ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê³µë°± ì œê±°
                return response.json()["response"].strip()
            else:
                # HTTP ì˜¤ë¥˜ ì‹œ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                
        except requests.exceptions.Timeout:
            # íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜ ì²˜ë¦¬ (8GB RAMì—ì„œ ìì£¼ ë°œìƒ ê°€ëŠ¥)
            return "ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        except Exception as e:
            # ê¸°íƒ€ ëª¨ë“  ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def get_interview_prompt(self, interview_type: str, is_first: bool = False) -> str:
        """
        ë©´ì ‘ ìœ í˜•ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            interview_type (str): ë©´ì ‘ ìœ í˜• ('ê³µë¬´ì›', 'ê³µê¸°ì—…', 'IT', 'ì‚¬ê¸°ì—…')
            is_first (bool): ì²« ë²ˆì§¸ ì§ˆë¬¸ ì—¬ë¶€
            
        Returns:
            str: AI ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        
        # ê° ë©´ì ‘ ìœ í˜•ë³„ íŠ¹ì„±í™”ëœ ë©´ì ‘ê´€ ì—­í•  ì •ì˜
        type_prompts = {
            "ê³µë¬´ì›": """ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ê¸°ê´€ì˜ ê²½í—˜ì´ í’ë¶€í•œ ê³µë¬´ì› ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê³µì§ê°€ì¹˜, ë´‰ì‚¬ì •ì‹ , ê³µì •ì„±, ì²­ë ´ì„±ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ì§€ì›ë™ê¸°, ê³µì§ê´€, ê°ˆë“±í•´ê²°, ì‹œë¯¼ì„œë¹„ìŠ¤, ì •ì±…ì´í•´ë„, êµ­ë¯¼ì— ëŒ€í•œ ë´‰ì‚¬ì •ì‹ """,
            
            "ê³µê¸°ì—…": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ê³µê¸°ì—… ì¸ì‚¬ë‹´ë‹¹ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê³µê³µì„±ê³¼ íš¨ìœ¨ì„±, ì „ë¬¸ì„±ê³¼ í˜ì‹ ì„ ê· í˜•ìˆê²Œ í‰ê°€í•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ê¸°ì—…ì´í•´ë„, ì „ë¬¸ì„±, ì‚¬íšŒì ì±…ì„, í˜ì‹ ì•„ì´ë””ì–´, ì¡°ì§ì í•©ì„±, ê³µê¸°ì—… ì—­í• """,
            
            "IT": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ìœ ëª…í•œ IT ê¸°ì—… ê¸°ìˆ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ê¸°ìˆ ì—­ëŸ‰, ë¬¸ì œí•´ê²°ëŠ¥ë ¥, í•™ìŠµëŠ¥ë ¥, í˜‘ì—…ëŠ¥ë ¥ì„ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ê¸°ìˆ ê²½í—˜, í”„ë¡œì íŠ¸ì‚¬ë¡€, ë¬¸ì œí•´ê²°, ìµœì‹ ê¸°ìˆ ë™í–¥, íŒ€ì›Œí¬, ì½”ë”©ì‹¤ë ¥""",
            
            "ì‚¬ê¸°ì—…": """ë‹¹ì‹ ì€ í•œêµ­ì˜ ëŒ€ê¸°ì—… ì¸ì‚¬ë‹´ë‹¹ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì™„ë²½í•œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë©´ì ‘ íŠ¹ì§•: ì„±ê³¼ì§€í–¥ì„±, ì ì‘ë ¥, ë¦¬ë”ì‹­, íšŒì‚¬ê¸°ì—¬ë„ë¥¼ ì¤‘ì‹œí•©ë‹ˆë‹¤.
ì£¼ìš” ì§ˆë¬¸ ì˜ì—­: ì§€ì›ë™ê¸°, ì„±ì·¨ê²½í—˜, ëª©í‘œì˜ì‹, ìŠ¤íŠ¸ë ˆìŠ¤ê´€ë¦¬, ë¯¸ë˜ê³„íš, íšŒì‚¬ì í•©ì„±"""
        }
        
        # ê³µí†µ ë©´ì ‘ ì§„í–‰ ì§€ì¹¨ (ëª¨ë“  ë©´ì ‘ ìœ í˜•ì— ì ìš©)
        base_prompt = f"""{type_prompts[interview_type]}

ì¤‘ìš”í•œ ë©´ì ‘ ì§„í–‰ ì§€ì¹¨:
- ë°˜ë“œì‹œ í‘œì¤€ í•œêµ­ì–´ë¡œë§Œ ëŒ€í™”í•˜ì„¸ìš” (ì ˆëŒ€ ì¼ë³¸ì–´, ì¤‘êµ­ì–´, ì˜ì–´ ê¸ˆì§€)
- ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ í•œêµ­ì–´ ì¡´ëŒ“ë§ ì‚¬ìš©
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ëª…í™•í•œ ì§ˆë¬¸ë§Œ ì œì‹œ
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ êµ¬ì²´ì ì¸ ì§ˆë¬¸ ìœ„ì£¼
- ì§€ì›ì ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•˜ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°± ì œê³µ
- í•œêµ­ì˜ ë©´ì ‘ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”

í˜„ì¬ ë©´ì ‘ ì§„í–‰ ìƒí™©: {self.question_count + 1}ë²ˆì§¸ ì§ˆë¬¸ (ì´ {self.max_questions}ê°œ ì˜ˆì •)"""

        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ ê²½ìš°ì˜ í”„ë¡¬í”„íŠ¸
        if is_first:
            return f"""{base_prompt}

ì§€ê¸ˆ {interview_type} ë©´ì ‘ì„ ì‹œì‘í•©ë‹ˆë‹¤. 
í•œêµ­ì˜ ë©´ì ‘ê´€ë‹µê²Œ ì •ì¤‘í•œ ì¸ì‚¬ë§ê³¼ í•¨ê»˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì™¸êµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""
        
        # í›„ì† ì§ˆë¬¸ì¸ ê²½ìš°ì˜ í”„ë¡¬í”„íŠ¸ (ëŒ€í™” ë§¥ë½ í¬í•¨)
        else:
            # ìµœê·¼ ëŒ€í™” ë‚´ì—­ êµ¬ì„± (ìµœëŒ€ 2ê°œì˜ ì´ì „ ëŒ€í™”ë§Œ í¬í•¨í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ìµœì í™”)
            recent_history = ""
            if self.conversation_history:
                recent = self.conversation_history[-2:]  # ìµœê·¼ 2ê°œ ëŒ€í™”ë§Œ ì„ íƒ
                for conv in recent:
                    recent_history += f"ë©´ì ‘ê´€: {conv['interviewer']}\nì§€ì›ì: {conv['user']}\n\n"
            
            return f"""{base_prompt}

ìµœê·¼ ëŒ€í™” ë‚´ìš©:
{recent_history}

ì§€ì›ìì˜ ë‹µë³€ì— ëŒ€í•´ ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ì£¼ê³ , ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì™¸êµ­ì–´ë¥¼ ì„ì§€ ë§ˆì„¸ìš”.
ë‹µë³€ì´ êµ¬ì²´ì ì´ê³  ì¢‹ë‹¤ë©´ ê²©ë ¤í•˜ê³ , ë¶€ì¡±í•˜ë‹¤ë©´ ë” ìì„¸í•œ ì„¤ëª…ì„ ì •ì¤‘í•˜ê²Œ ìš”ì²­í•˜ì„¸ìš”."""
    
    def start_interview(self, interview_type: str) -> str:
        """
        ìƒˆë¡œìš´ ë©´ì ‘ ì„¸ì…˜ ì‹œì‘
        
        Args:
            interview_type (str): ì‹œì‘í•  ë©´ì ‘ ìœ í˜•
            
        Returns:
            str: AI ë©´ì ‘ê´€ì˜ ì²« ë²ˆì§¸ ì¸ì‚¬ë§ ë° ì§ˆë¬¸
        """
        # ë©´ì ‘ ìƒíƒœ ì´ˆê¸°í™”
        self.interview_type = interview_type    # ë©´ì ‘ ìœ í˜• ì €ì¥
        self.conversation_history = []          # ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”
        self.question_count = 0                 # ì§ˆë¬¸ ë²ˆí˜¸ ì´ˆê¸°í™”
        
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.get_interview_prompt(interview_type, is_first=True)
        
        # AI ëª¨ë¸ì—ê²Œ ì²« ì§ˆë¬¸ ìš”ì²­
        response = self.call_ollama(prompt)
        
        # ì§ˆë¬¸ ì¹´ìš´í„° ì¦ê°€
        self.question_count = 1
        
        return response
    
    def process_answer(self, user_answer: str) -> tuple[str, bool]:
        """
        ì§€ì›ì ë‹µë³€ ì²˜ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
        
        Args:
            user_answer (str): ì§€ì›ìê°€ ì…ë ¥í•œ ë‹µë³€
            
        Returns:
            tuple[str, bool]: (AI ë©´ì ‘ê´€ ì‘ë‹µ, ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€)
        """
        
        # ë©´ì ‘ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        if self.question_count >= self.max_questions:
            # ìµœëŒ€ ì§ˆë¬¸ ìˆ˜ì— ë„ë‹¬í–ˆì„ ë•Œ ë©´ì ‘ ì¢…ë£Œ ì²˜ë¦¬
            prompt = f"""ë©´ì ‘ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 
ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€: {user_answer}

í•œêµ­ì˜ ë©´ì ‘ê´€ë‹µê²Œ ì „ì²´ì ì¸ ë©´ì ‘ì— ëŒ€í•œ ì¢…í•© í”¼ë“œë°±ì„ ì •ì¤‘í•˜ê³  ë”°ëœ»í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
1. ì „ë°˜ì ì¸ ë©´ì ‘ íƒœë„ì™€ ì¸ìƒ
2. ì£¼ìš” ê°•ì  2-3ê°€ì§€
3. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ 1-2ê°€ì§€  
4. ì•ìœ¼ë¡œì˜ ë°œì „ì„ ìœ„í•œ ì¡°ì–¸
5. ê²©ë ¤ì™€ ì‘ì›ì˜ ë§ˆë¬´ë¦¬ ì¸ì‚¬

ë°˜ë“œì‹œ ì™„ë²½í•œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ê³  ê²©ë ¤ì˜ ë§ì”€ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”."""
            
            # ì¢…í•© í‰ê°€ ìƒì„±
            response = self.call_ollama(prompt)
            return response, True  # ë©´ì ‘ ì¢…ë£Œ í”Œë˜ê·¸ì™€ í•¨ê»˜ ë°˜í™˜
        
        # í˜„ì¬ ë‹µë³€ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        if self.conversation_history:
            # ë§ˆì§€ë§‰ ëŒ€í™”ì˜ ì‚¬ìš©ì ë‹µë³€ ë¶€ë¶„ ì—…ë°ì´íŠ¸
            self.conversation_history[-1]['user'] = user_answer
        
        # ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.get_interview_prompt(self.interview_type)
        prompt += f"\n\nì§€ì›ìì˜ ìµœê·¼ ë‹µë³€: {user_answer}\n\nì´ ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•œ í”¼ë“œë°±ê³¼ í•¨ê»˜ ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
        
        # AI ëª¨ë¸ì—ê²Œ ë‹¤ìŒ ì§ˆë¬¸ ìš”ì²­
        response = self.call_ollama(prompt)
        
        # ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ë©´ì ‘ê´€ ì§ˆë¬¸ë§Œ ë¨¼ì € ì €ì¥)
        self.conversation_history.append({
            'interviewer': response,  # AI ë©´ì ‘ê´€ì˜ ì‘ë‹µ
            'user': None             # ì‚¬ìš©ì ë‹µë³€ì€ ë‹¤ìŒ ë¼ìš´ë“œì—ì„œ ì €ì¥
        })
        
        # ì§ˆë¬¸ ë²ˆí˜¸ ì¦ê°€
        self.question_count += 1
        
        return response, False  # ë©´ì ‘ ê³„ì† ì§„í–‰

# =============================================================================
# Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ë©”ì¸ í•¨ìˆ˜
# =============================================================================

def main():
    """
    Streamlit ê¸°ë°˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ì¸ í•¨ìˆ˜
    
    ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±:
    1. í˜ì´ì§€ ì„¤ì • ë° ì œëª©
    2. ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    3. ì‚¬ì´ë“œë°” (ì‹œìŠ¤í…œ ìƒíƒœ, ë©´ì ‘ ì„¤ì •)
    4. ë©”ì¸ ì½˜í…ì¸  (ë©´ì ‘ ì§„í–‰)
    """
    
    # Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
    st.set_page_config(
        page_title="AI ë©´ì ‘ ì‹œìŠ¤í…œ",    # ë¸Œë¼ìš°ì € íƒ­ ì œëª©
        page_icon="ğŸ‡°ğŸ‡·",              # ë¸Œë¼ìš°ì € íƒ­ ì•„ì´ì½˜
        layout="wide"                  # ì™€ì´ë“œ ë ˆì´ì•„ì›ƒ ì‚¬ìš©
    )
    
    # í˜ì´ì§€ í—¤ë”
    st.title("AI ëª¨ì˜ ë©´ì ‘ ì‹œìŠ¤í…œ")     # ë©”ì¸ ì œëª©
    st.caption("ğŸš€í•œêµ­ì–´ íŠ¹í™”")        # ë¶€ì œëª©
    
    # =============================================================================
    # Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    # =============================================================================
    # ì›¹ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ì‹œì—ë„ ë°ì´í„° ìœ ì§€ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
    
    if 'interview_system' not in st.session_state:
        # ë©´ì ‘ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í˜ì´ì§€ë‹¹ í•œ ë²ˆë§Œ)
        st.session_state.interview_system = OllamaInterviewSystem()
        
    if 'interview_started' not in st.session_state:
        # ë©´ì ‘ ì§„í–‰ ìƒíƒœ í”Œë˜ê·¸
        st.session_state.interview_started = False
        
    if 'messages' not in st.session_state:
        # í™”ë©´ì— í‘œì‹œí•  ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        st.session_state.messages = []
        
    if 'interview_finished' not in st.session_state:
        # ë©´ì ‘ ì™„ë£Œ ìƒíƒœ í”Œë˜ê·¸
        st.session_state.interview_finished = False
    
    # =============================================================================
    # ì‚¬ì´ë“œë°” êµ¬ì„±
    # =============================================================================
    with st.sidebar:
        st.title("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # Ollama ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸ ë° í‘œì‹œ
        is_connected = st.session_state.interview_system.check_ollama_connection()
        if is_connected:
            st.success("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ í‘œì‹œ
            models = st.session_state.interview_system.get_available_models()
            if models:
                st.info(f"ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\n{', '.join(models)}")
        else:
            # ì—°ê²° ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë° í•´ê²° ë°©ë²• ì œì‹œ
            st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.info("í•´ê²°ë°©ë²•:\n1. 'ollama serve' ì‹¤í–‰\n2. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨")
            return  # ì—°ê²°ë˜ì§€ ì•Šìœ¼ë©´ ì•± ì¢…ë£Œ
        
        # ë©´ì ‘ ì„¤ì • ì„¹ì…˜ (ë©´ì ‘ ì‹œì‘ ì „ì—ë§Œ í‘œì‹œ)
        if not st.session_state.interview_started:
            st.divider()  # êµ¬ë¶„ì„ 
            st.subheader("ğŸ“‹ ë©´ì ‘ ì„¤ì •")
            
            # ë©´ì ‘ ìœ í˜• ì„ íƒ ë“œë¡­ë‹¤ìš´
            interview_types = {
                "ğŸ›ï¸ ê³µë¬´ì›": "ê³µë¬´ì›",
                "ğŸ¢ ê³µê¸°ì—…": "ê³µê¸°ì—…", 
                "ğŸ’» IT": "IT",
                "ğŸª ì‚¬ê¸°ì—…": "ì‚¬ê¸°ì—…"
            }
            
            selected = st.selectbox(
                "ë©´ì ‘ ìœ í˜• ì„ íƒ:",
                options=list(interview_types.keys())
            )
            # ì„ íƒëœ ë©´ì ‘ ìœ í˜•ì„ ì„¸ì…˜ì— ì €ì¥
            st.session_state.selected_type = interview_types[selected]
            
            # ì„ íƒëœ ë©´ì ‘ ìœ í˜•ì˜ íŠ¹ì§• ì •ë³´ í‘œì‹œ
            st.info(f"""
**{interview_types[selected]} ë©´ì ‘ íŠ¹ì§•:**
- ì´ {st.session_state.interview_system.max_questions}ê°œ ì§ˆë¬¸ ì˜ˆì •
- í•œêµ­ì–´ íŠ¹í™” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ êµ¬ì²´ì  ì§ˆë¬¸
- ë‹µë³€ë³„ ì¦‰ì‹œ í”¼ë“œë°± ì œê³µ
            """)
        else:
            # ë©´ì ‘ ì§„í–‰ ì¤‘ì¼ ë•Œ ì§„í–‰ë¥  í‘œì‹œ
            st.subheader("ğŸ“Š ë©´ì ‘ ì§„í–‰ë¥ ")
            progress = st.session_state.interview_system.question_count
            max_q = st.session_state.interview_system.max_questions
            
            # ì§„í–‰ë¥  ë°” í‘œì‹œ
            st.progress(progress / max_q)
            st.write(f"ì§„í–‰ë¥ : {progress}/{max_q}")
            st.write(f"ë©´ì ‘ ìœ í˜•: {st.session_state.interview_system.interview_type}")
            
            # ë©´ì ‘ ì¤‘ë‹¨ ë²„íŠ¼
            if st.button("ğŸ›‘ ë©´ì ‘ ì¤‘ë‹¨", type="secondary"):
                # ëª¨ë“  ë©´ì ‘ ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.interview_started = False
                st.session_state.messages = []
                st.session_state.interview_finished = False
                st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
    
    # =============================================================================
    # ë©”ì¸ ì½˜í…ì¸  ì˜ì—­
    # =============================================================================
    
    if not st.session_state.interview_started:
        # =============================================================================
        # ë©´ì ‘ ì‹œì‘ ì „ í™”ë©´
        # =============================================================================
        col1, col2, col3 = st.columns([1, 2, 1])  # 3ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ì¤‘ì•™ ì§‘ì¤‘)
        with col2:
            st.markdown("### ğŸ¯ ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ!")
            
            # ì„ íƒëœ ë©´ì ‘ ìœ í˜•ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ í‘œì‹œ
            if hasattr(st.session_state, 'selected_type'):
                st.info(f"**ì„ íƒëœ ë©´ì ‘:** {st.session_state.selected_type}")
                
                # ë©´ì ‘ ì§„í–‰ ë°©ì‹ ì•ˆë‚´
                st.markdown("""
                **ğŸ’¡ ë©´ì ‘ ì§„í–‰ ë°©ì‹:**
- AI ë©´ì ‘ê´€ì´ ì™„ë²½í•œ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•©ë‹ˆë‹¤
- ì‹¤ë¬´ ì¤‘ì‹¬ì˜ ì „ë¬¸ì ì¸ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤  
- ê° ë‹µë³€ì— ëŒ€í•´ ì¦‰ì‹œ í•œêµ­ì–´ í”¼ë“œë°±ì„ ë°›ìŠµë‹ˆë‹¤
- í•œêµ­ì˜ ë©´ì ‘ ë¬¸í™”ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤
- ë©´ì ‘ ì™„ë£Œ í›„ ì¢…í•© í‰ê°€ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•©ë‹ˆë‹¤
                """)
                
                # ë©´ì ‘ ì‹œì‘ ë²„íŠ¼
                if st.button("ğŸš€ ë©´ì ‘ ì‹œì‘í•˜ê¸°!", type="primary", use_container_width=True):
                    # ë¡œë”© ë©”ì‹œì§€ì™€ í•¨ê»˜ ë©´ì ‘ ì‹œì‘
                    with st.spinner("AI ë©´ì ‘ê´€ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        # ì„ íƒëœ ìœ í˜•ìœ¼ë¡œ ë©´ì ‘ ì‹œì‘
                        response = st.session_state.interview_system.start_interview(
                            st.session_state.selected_type
                        )
                        
                        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ë¥¼ í™”ë©´ í‘œì‹œìš© ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        st.session_state.messages = [
                            {
                                "role": "assistant",       # AI ë©´ì ‘ê´€ ì—­í• 
                                "content": response,        # ë©´ì ‘ê´€ì˜ ì²« ì¸ì‚¬ë§
                                "timestamp": datetime.now() # ì‹œê°„ ê¸°ë¡
                            }
                        ]
                        
                        # ë©´ì ‘ ìƒíƒœ ë³€ê²½
                        st.session_state.interview_started = True
                        st.session_state.interview_finished = False
                        
                    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë©´ì ‘ í™”ë©´ìœ¼ë¡œ ì „í™˜
    
    else:
        # =============================================================================
        # ë©´ì ‘ ì§„í–‰ ì¤‘ í™”ë©´
        # =============================================================================
        st.markdown("### ğŸ’¬ ë©´ì ‘ ì§„í–‰")
        
        # ëŒ€í™” ë‚´ì—­ í‘œì‹œ (ì±—ë´‡ ìŠ¤íƒ€ì¼)
        for message in st.session_state.messages:
            if message["role"] == "assistant":
                # AI ë©´ì ‘ê´€ ë©”ì‹œì§€ (ì™¼ìª½, í•œêµ­ êµ­ê¸° ì•„ë°”íƒ€)
                with st.chat_message("assistant", avatar="ğŸ‡°ğŸ‡·"):
                    st.write(message["content"])
                    # ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                    if "timestamp" in message:
                        st.caption(f"ğŸ• {message['timestamp'].strftime('%H:%M:%S')}")
            else:
                # ì‚¬ìš©ì ë©”ì‹œì§€ (ì˜¤ë¥¸ìª½, ì‚¬ëŒ ì•„ë°”íƒ€)
                with st.chat_message("user", avatar="ğŸ‘¤"):
                    st.write(message["content"])
                    if "timestamp" in message:
                        st.caption(f"ğŸ• {message['timestamp'].strftime('%H:%M:%S')}")
        
        # =============================================================================
        # ë‹µë³€ ì…ë ¥ í¼ (ë©´ì ‘ì´ ëë‚˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)
        # =============================================================================
        if not st.session_state.interview_finished:
            with st.form("answer_form", clear_on_submit=True):  # ì œì¶œ í›„ ìë™ í´ë¦¬ì–´
                # ë‹µë³€ ì…ë ¥ í…ìŠ¤íŠ¸ ë°•ìŠ¤
                user_input = st.text_area(
                    "ğŸ’­ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    height=120,                                    # ë†’ì´ ì„¤ì •
                    placeholder="ë©´ì ‘ê´€ì˜ ì§ˆë¬¸ì— êµ¬ì²´ì ì´ê³  ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”...",  # íŒíŠ¸ í…ìŠ¤íŠ¸
                    help="Enterë¥¼ ëˆŒëŸ¬ì„œ ì¤„ë°”ê¿ˆí•˜ê³ , ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ë‹µë³€ì„ ì œì¶œí•˜ì„¸ìš”."    # ë„ì›€ë§
                )
                
                # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ (4:1 ë¹„ìœ¨)
                col1, col2 = st.columns([4, 1])
                with col1:
                    submitted = st.form_submit_button("ğŸ“¤ ë‹µë³€ ì œì¶œ", type="primary")
                with col2:
                    skip = st.form_submit_button("â­ï¸ ê±´ë„ˆë›°ê¸°")
                
                # ë‹µë³€ ì œì¶œ ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬
                if submitted and user_input.strip():
                    # ì‚¬ìš©ì ë‹µë³€ì„ í™”ë©´ í‘œì‹œìš© ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "user", 
                        "content": user_input,
                        "timestamp": datetime.now()
                    })
                    
                    # AI ì‘ë‹µ ìƒì„± (ë¡œë”© í‘œì‹œì™€ í•¨ê»˜)
                    with st.spinner("ë©´ì ‘ê´€ì´ ë‹µë³€ì„ ê²€í† í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        ai_response, is_finished = st.session_state.interview_system.process_answer(user_input)
                    
                    # AI ì‘ë‹µì„ í™”ë©´ í‘œì‹œìš© ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": ai_response,
                        "timestamp": datetime.now()
                    })
                    
                    # ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
                    if is_finished:
                        st.session_state.interview_finished = True
                        st.balloons()  # ì¶•í•˜ ì• ë‹ˆë©”ì´ì…˜ í‘œì‹œ
                    
                    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ìƒˆ ë©”ì‹œì§€ í‘œì‹œ
                
                # ê±´ë„ˆë›°ê¸° ë²„íŠ¼ í´ë¦­ ì‹œ ì²˜ë¦¬
                elif skip:
                    # ê±´ë„ˆë›°ê¸° ë©”ì‹œì§€ë¡œ ë‹µë³€ ì²˜ë¦¬
                    skip_response, is_finished = st.session_state.interview_system.process_answer("ì£„ì†¡í•˜ì§€ë§Œ ì´ ì§ˆë¬¸ì€ ê±´ë„ˆë›°ê² ìŠµë‹ˆë‹¤.")
                    
                    # AI ì‘ë‹µë§Œ ì¶”ê°€ (ì‚¬ìš©ì ì…ë ¥ì€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": skip_response,
                        "timestamp": datetime.now()
                    })
                    
                    # ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
                    if is_finished:
                        st.session_state.interview_finished = True
                    
                    st.rerun()
                
                # ë¹ˆ ë‹µë³€ ì œì¶œ ì‹œ ê²½ê³ 
                elif submitted:
                    st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        else:
            # =============================================================================
            # ë©´ì ‘ ì™„ë£Œ í›„ í™”ë©´
            # =============================================================================
            st.success("ğŸ‰ í•œêµ­ì–´ ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # 3ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë²„íŠ¼ ë°°ì¹˜
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # ìƒˆ ë©´ì ‘ ì‹œì‘ ë²„íŠ¼
                if st.button("ğŸ”„ ìƒˆ ë©´ì ‘ ì‹œì‘", type="primary"):
                    # ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”í•˜ì—¬ ìƒˆ ë©´ì ‘ ì¤€ë¹„
                    st.session_state.interview_started = False
                    st.session_state.messages = []
                    st.session_state.interview_finished = False
                    st.rerun()
            
            with col2:
                # ëŒ€í™” ë‚´ì—­ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
                if st.session_state.messages:
                    # ë©´ì ‘ ê¸°ë¡ì„ í…ìŠ¤íŠ¸ íŒŒì¼ í˜•íƒœë¡œ ìƒì„±
                    conversation_text = f"ğŸ‡°ğŸ‡· í•œêµ­ì–´ AI ë©´ì ‘ ê¸°ë¡\n"
                    conversation_text += f"ë©´ì ‘ ìœ í˜•: {st.session_state.interview_system.interview_type}\n"
                    conversation_text += f"ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                    conversation_text += "=" * 50 + "\n\n"
                    
                    # ëª¨ë“  ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    for msg in st.session_state.messages:
                        role = "ğŸ‡°ğŸ‡· ë©´ì ‘ê´€" if msg["role"] == "assistant" else "ğŸ‘¤ ì§€ì›ì"
                        timestamp = msg.get("timestamp", datetime.now()).strftime('%H:%M:%S')
                        conversation_text += f"[{timestamp}] {role}:\n{msg['content']}\n\n"
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                    st.download_button(
                        label="ğŸ’¾ ë©´ì ‘ ê¸°ë¡ ì €ì¥",
                        data=conversation_text,                                                    # ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°
                        file_name=f"korean_interview_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",  # íŒŒì¼ëª… (ë‚ ì§œì‹œê°„ í¬í•¨)
                        mime="text/plain"                                                          # íŒŒì¼ í˜•ì‹
                    )
            
            with col3:
                # ë©´ì ‘ í†µê³„ ì •ë³´ í‘œì‹œ
                total_questions = len([m for m in st.session_state.messages if m["role"] == "assistant"])
                st.metric("ì´ ì§ˆë¬¸ ìˆ˜", total_questions)

# =============================================================================
# í”„ë¡œê·¸ë¨ ì§„ì…ì 
# =============================================================================

if __name__ == "__main__":
    """
    í”„ë¡œê·¸ë¨ì˜ ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
    
    Python ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ main() í•¨ìˆ˜ í˜¸ì¶œ
    (ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importí•  ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ)
    """
    main()
